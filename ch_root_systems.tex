\chapter{Root Systems}
\label{cha:root_systems}

A \defn{Euclidean space} is is a vector space $E\isomorphic \RR^n$ equipped with a positive definite symmetric bilinear form $(\cdot,\cdot): E\times E \to \RR$. A reflection about any nonzero vector $\alpha$ is defined as
\begin{align}
    \sigma_\alpha(\beta) &= \beta - 2 \frac{(\beta,\alpha)}{(\alpha,\alpha)} \alpha
\end{align}
with the reflecting hyperplane given by
\begin{align}
    P_\alpha &= \{\beta\in E \ |\ (\beta,\alpha)=0\}.
\end{align}
We use the shorthand $\<\beta,\alpha\>=2 \frac{(\beta,\alpha)}{(\alpha,\alpha)}$.

A subset $\Phi$ of the euclidean space $E$ is called a \defn{reduced root system} in $E$ if the following axioms are satisfied:
\begin{enumerate}[(R1)]
    \makethislistcompact
    \item $\Phi$ is finite, spans $E$ and $\Phi\not\ni 0$.
    \item If $\alpha\in \Phi$, the only multiples of $\alpha$ in $\Phi$ are $\pm \alpha$.
    \item If $\alpha\in\Phi$, the reflection $\sigma_\alpha$ leaves $\Phi$ invariant.
    \item If $\alpha,\beta\in \Phi$, then $\<\beta,\alpha\>\in \ZZ$
\end{enumerate}

\begin{insight}
    If axiom (R2) is removed, then we get a \defn{root system} (no longer \emph{reduced}). This is useful in the classification of real semisimple Lie algebras.
\end{insight}

Let $\Phi$ be a root system in $E$. Let $\Weyl$ denote the subgroup of $\GL(E)$ generated by the reflections $\sigma_\alpha$. 

By (R3), $\Weyl$ permutes the set $\Phi$, which by (R1).
$\Weyl$ is the Weyl group.

\begin{lemma}
    Let $\Phi$  be a root system in $E$, with Weyl group $\Weyl$. If $\sigma\in \GL(E)$ leaves $\Phi$ invariant, then $\sigma \sigma_\alpha \sigma^{-1} = \sigma_{\sigma(\alpha)}$ for $\alpha\in \Phi$ and $\<\beta,\alpha\>=\<\sigma(\alpha),\sigma(\beta)\>$  for all $\alpha,\beta \in \Phi$.
\end{lemma}
\begin{proof}
    
\end{proof}

\section{Bases}
\label{sec:bases}

A subset $\Delta \subset \Phi$ is called a \defn{base} if:
\begin{itemize}
    \makethislistcompact
    \item [(B1)] $\Delta$ is a basis of $E$
    \item [(B2)] each root $\beta$ can be written as a $\beta = \sum k_\alpha \alpha$ with $\alpha\in \Delta$ with integral coefficients all non-negative or nonpositive.
\end{itemize}

\begin{insight}
   \begin{lemma}
       A root is simple if and only if it cannot be written as a sum of other roots.
   \end{lemma} 
   \begin{proof}
       \Todo{Prove this.} 
   \end{proof}
\end{insight}

The roots in $\Delta$ are called \defn{simple} (\Todo{Is the definition of simple relative to the base?}).
\Todo{Is Card $\Delta$= Dim $\Delta$}? 
Since $\Delta$ is a basis, the expression given by (B2) is unique. This lets us define the \defn{height} of a root (relative to $\Delta$) by 
\begin{align}
    \height \beta = \sum_{\alpha\in \Delta} k_\alpha
\end{align}
A root is \defn{positive} if all $k_\alpha\geq0$ and \defn{negative} if all $k_\alpha<0$. The set of all positive roots is denoted by $\Phi^+$ and the set of all negative roots is given by $\Phi^-$.

We need to show that a base defined as above actually exists. We do this by explicit construction. But first, we need 
\begin{lemma}
    If $\Delta$ is a base of $\Phi$, then $(\alpha,\beta)\leq 0$  for all $\alpha\neq\beta$ in $\Delta$, and $\alpha-\beta$ is not a root.
\end{lemma}
\begin{proof}
    We have, by an earlier lemma (\Todo{reference}) that if $(\alpha,\beta)>0$ then $\alpha - \beta$ is a root. The logical negation of that statement is that if $\alpha + \beta$ is not a root, then $(\alpha,\beta)\leq 0$. But $\alpha-\beta$ can not be a root since that would violate that the second axiom (B2) that all coefficients must have the same sign.
\end{proof}
\begin{theorem}
    Bases exist.
\end{theorem}
    For a vector $\gamma\in E$, define 
    \begin{align}
        \Phi^+(\gamma) = \{\alpha\in\Phi\ |\ (\gamma,\alpha)>0\}.
    \end{align}
    This is just the set of all vectors lying to the \emph{positive} side of the hyperplane orthogonal to $\gamma$, given by $P_\gamma$. 
    \begin{insight}
        Any finite union of hyperplanes in a euclidean space cannot exhaust all of the space. If you hyperplanes corresponding to vectors $S=\{\alpha_1,\dotsc,\alpha_n\}$, take a linearly independent subset of $S$ that spans $\<S\>$. The number of vectors in the subset must be less than or equal to $\dim E$. \Todo{Complete this}
    \end{insight}

    A $\gamma\in E$ is \defn{regular} if $\gamma\in E - \bigcup_{\alpha\in\Phi}P_\alpha$, \defn{singular} otherwise.

    Given a vector $\gamma$ and a root $\alpha$, you could have $(\gamma,\alpha)$ less than, greater than, or equal to 0. If it vanishes, then it is singular by definition. Now, if it is regular then all the roots are on either side of the $P_\gamma$, so $\Phi = \Phi^+(\gamma)\cup \Phi^-(\gamma)$. Call $\alpha\in \Phi^+$ \defn{decomposable} if $\alpha = \beta_1 + \beta_2$ for some $\beta_i\in \Phi^+(\gamma)$, \defn{indecomposable} otherwise.

\begin{theorem}
    Let $\gamma\in E$ be regular. Then the set $\Delta(\gamma)$  of all indecomposable roots in $\Phi^+(\gamma)$ is a base of $\Phi$, and every base is obtainable in this manner.
\end{theorem}
\begin{proof}
\end{proof}

